{
  "metadata": {
    "repository": "https://github.com/b08x/omega-13",
    "generated_at": "2025-12-29T02:01:00.453045",
    "page_count": 12
  },
  "pages": [
    {
      "id": "introduction",
      "title": "Introduction to Omega-13",
      "content": "<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n- [src/omega13/app.py](https://github.com/b08x/omega-13/blob/main/src/omega13/app.py)\n- [src/omega13/audio.py](https://github.com/b08x/omega-13/blob/main/src/omega13/audio.py)\n- [src/omega13/session.py](https://github.com/b08x/omega-13/blob/main/src/omega13/session.py)\n- [src/omega13/transcription.py](https://github.com/b08x/omega-13/blob/main/src/omega13/transcription.py)\n- [src/omega13/config.py](https://github.com/b08x/omega-13/blob/main/src/omega13/config.py)\n- [README.md](https://github.com/b08x/omega-13/blob/main/README.md)\n</details>\n\n# Introduction to Omega-13\n\nOmega-13 is a retroactive audio recording and transcription system designed to capture audio data that occurred prior to the initiation of a recording command. The system operates as a terminal user interface (TUI) application that maintains a continuous rolling buffer of audio in memory, allowing users to \"recover\" the preceding 13 seconds of audio.\n\nSources: [README.md](), [src/omega13/app.py]()\n\n## System Architecture and Mechanism\n\nThe system is built on a modular architecture where the `Omega13App` coordinates several specialized components. It utilizes the JACK/PipeWire audio infrastructure for low-latency audio capture and a local Docker-based Whisper server for AI transcription.\n\n### Core Components\n\n| Component | Responsibility |\n| :--- | :--- |\n| `AudioEngine` | Manages JACK client, maintains the 13-second ring buffer, and handles file writing. |\n| `SessionManager` | Oversees session lifecycles, directory structures, and metadata persistence. |\n| `TranscriptionService` | Interfaces with a local HTTP API to convert audio files into text. |\n| `ConfigManager` | Handles persistent JSON-based settings and hardware port mappings. |\n| `Omega13App` | Provides the Textual-based TUI and binds global hotkeys to system actions. |\n\nSources: [src/omega13/audio.py:#L18-L25](), [src/omega13/session.py](), [src/omega13/config.py:#L11-L20](), [src/omega13/app.py:#L45-L65]()\n\n## Audio Processing Flow\n\nThe `AudioEngine` maintains a `ring_buffer` using NumPy, which stores `float32` audio data. This buffer is constantly updated in the background. When a recording is triggered, the engine \"stitches\" the historical data from the ring buffer with the incoming real-time audio stream.\n\n```mermaid\ngraph TD\n    A[JACK/PipeWire Input] --> B{AudioEngine}\n    B --> C[13s Ring Buffer]\n    B --> D[Real-time Queue]\n    E[Hotkey Trigger] --> F[Stitcher Logic]\n    C --> F\n    D --> F\n    F --> G[SoundFile .wav Output]\n```\n\nThe \"stitcher\" logic is a clever way to handle the temporal shift, though it relies heavily on the `writer_thread` keeping up with the `record_queue`. If the queue overflows (maxsize=200), audio data is simply lost\u2014a shitty but pragmatic constraint for a real-time system.\n\nSources: [src/omega13/audio.py:#L36-L55](), [README.md]()\n\n## Session and Transcription Lifecycle\n\nSessions are initially volatile, stored in `/tmp/omega13`. A session becomes permanent only when explicitly saved by the user. The transcription process is decoupled from recording; it occurs via an HTTP POST request to a local container.\n\n### Interaction Sequence\n\nThe following diagram illustrates the sequence from hotkey trigger to clipboard update:\n\n```mermaid\nsequenceDiagram\n    participant U as User/Hotkey\n    participant A as Omega13App\n    participant E as AudioEngine\n    participant S as SessionManager\n    participant T as TranscriptionService\n    \n    U->>A: Trigger Global Hotkey\n    A->>E: Start/Stop Recording\n    E->>S: Write .wav to Session Dir\n    A->>T: Request Transcription(path)\n    activate T\n    T->>T: HTTP POST to whisper-server\n    T-->>A: Return TranscriptionResult\n    deactivate T\n    A->>A: Update UI & Copy to Clipboard\n```\n\nSources: [src/omega13/app.py:#L120-L140](), [src/omega13/transcription.py:#L45-L60](), [README.md]()\n\n## Structural Observations and Inconsistencies\n\nA notable structural pattern is the system's dependency on external environmental factors that are not strictly managed by the Python code. For instance:\n- **Wayland Constraints:** The application cannot natively listen for global hotkeys under Wayland. It forces the user to manually configure a system-level shortcut to execute `omega13 --toggle`, which then pokes the running instance via a PID file. It\u2019s a functional workaround that highlights the fragmented nature of Linux desktop automation.\n- **Transcription Redundancy:** The `Session` class contains a word-based deduplication algorithm in `add_transcription`. This suggests that the underlying transcription service or the way audio is fed to it occasionally produces overlapping text segments, requiring the application layer to clean up the mess.\n- **Silent Failures:** The `AudioEngine` checks for signal levels to prevent \"empty\" recordings. If the VU meter doesn't move, the capture is blocked. While this prevents disk bloat, it introduces a failure state where the user might think they are recording when they are not, simply because the input gain was too low.\n\nSources: [src/omega13/session.py:#L1-L30](), [src/omega13/app.py:#L150-L170](), [README.md]()\n\n## Configuration and Persistence\n\nThe `ConfigManager` defaults to `~/.config/omega13/config.json`. It tracks hardware-specific details like JACK input ports, which are essential because the app \"listens to nothing\" by default until the user maps ports in the UI.\n\n| Field | Default Value | Description |\n| :--- | :--- | :--- |\n| `global_hotkey` | `<ctrl>+<alt>+space` | The sequence used for the TUI listener. |\n| `server_url` | `http://localhost:8080` | The endpoint for the Whisper Docker container. |\n| `buffer_duration` | 13 | Hardcoded constant for the \"time machine\" effect. |\n\nSources: [src/omega13/config.py:#L25-L40](), [src/omega13/audio.py:#L14]()\n\n## Conclusion\n\nOmega-13 is structurally defined by its role as a temporal bridge for audio. Its significance lies in the integration of high-performance audio buffering (JACK/NumPy) with high-latency AI processing (Whisper). The system exhibits a heavy reliance on local infrastructure (Docker, PID files, and specific JACK/PipeWire configurations), making it a specialized tool for Linux environments where such low-level control is accessible.",
      "filePaths": [
        "README.md"
      ],
      "importance": "high",
      "relatedPages": [
        "getting-started"
      ]
    },
    {
      "id": "getting-started",
      "title": "Getting Started",
      "content": "<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n- [src/omega13/app.py](https://github.com/b08x/omega-13/blob/main/src/omega13/app.py)\n- [src/omega13/config.py](https://github.com/b08x/omega-13/blob/main/src/omega13/config.py)\n- [src/omega13/audio.py](https://github.com/b08x/omega-13/blob/main/src/omega13/audio.py)\n- [src/omega13/session.py](https://github.com/b08x/omega-13/blob/main/src/omega13/session.py)\n- [src/omega13/transcription.py](https://github.com/b08x/omega-13/blob/main/src/omega13/transcription.py)\n- [README.md](https://github.com/b08x/omega-13/blob/main/README.md)\n</details>\n\n# Getting Started\n\n## 1. Introduction\nOmega-13 is a retroactive audio recording system designed to capture audio buffers from the past (defaulting to 13 seconds) and process them through a transcription pipeline. The system operates as a Terminal User Interface (TUI) application built on the Textual framework, coordinating between a JACK-based audio engine, a local or containerized Whisper transcription server, and a session management layer. Its primary role is to bridge the gap between continuous audio monitoring and on-demand archival/transcription.\n\nSources: [src/omega13/app.py:#L57-L80](), [README.md:#L76-L85]()\n\n## 2. System Architecture and Initialization\nThe application initializes by loading persistent configurations and establishing a JACK client. The boot sequence reveals a dependency chain where the UI cannot effectively function without a valid audio backend, yet the system allows the UI to launch even if inputs are unconfigured.\n\n### Component Interaction Flow\nThe following diagram illustrates the startup and input connection sequence:\n\n```mermaid\ngraph TD\n    A[Main Entry Point] --> B[ConfigManager]\n    B --> C[Omega13App Initialization]\n    C --> D[AudioEngine Setup]\n    D --> E[JACK Client Registration]\n    E --> F[SessionManager Creation]\n    F --> G[TUI Render]\n    G --> H{Input Ports Configured?}\n    H -- No --> I[Display: Inputs Not Configured]\n    H -- Yes --> J[Connect JACK Ports]\n    J --> K[Start Audio Ring Buffer]\n```\nSources: [src/omega13/app.py:#L125-L150](), [src/omega13/audio.py:#L22-L40]()\n\n### Core Components\n| Component | Responsibility | Key Interaction |\n| :--- | :--- | :--- |\n| `ConfigManager` | Persists user settings (hotkeys, server URLs, paths) in `~/.config/omega13/config.json`. | Provides the `global_hotkey` and `server_url` to the app. |\n| `AudioEngine` | Manages a `numpy`-based ring buffer and handles real-time audio capture via JACK. | Feeds peak levels to the `VUMeter` UI components. |\n| `SessionManager` | Handles temporary storage in `/tmp/omega13` and permanent archival. | Triggers metadata syncing when transcriptions are added. |\n| `TranscriptionService` | Interfaces with a `whisper-server` HTTP API for asynchronous processing. | Updates the `TranscriptionDisplay` upon completion or error. |\n\nSources: [src/omega13/config.py:#L14-L40](), [src/omega13/audio.py:#L18-L55](), [src/omega13/session.py:#L45-L60](), [src/omega13/transcription.py:#L45-L65]()\n\n## 3. Configuration Mechanisms\nThe system relies on a JSON configuration file. A notable structural pattern is the hardcoded reliance on a specific versioning scheme (version 2) and a default \"retroactive\" window of 13 seconds, which is reflected in both the class constants and the project name.\n\n### Default Configuration Attributes\n| Field | Default Value | Purpose |\n| :--- | :--- | :--- |\n| `global_hotkey` | `<ctrl>+<alt>+space` | Trigger for starting/stopping the capture. |\n| `server_url` | `http://localhost:8080` | Endpoint for the Whisper transcription API. |\n| `save_path` | `Path.cwd()` | Default directory for permanent session storage. |\n| `buffer_duration`| 13 | Duration in seconds of the pre-record ring buffer. |\n\nSources: [src/omega13/config.py:#L30-L45](), [src/omega13/audio.py:#L15-L16]()\n\n## 4. Audio Capture and Hotkey Logic\nThe system uses a \"toggle\" mechanism to control recording. This is implemented via a CLI flag `--toggle` that sends signals to a running instance identified by a PID file. This approach bypasses Wayland's security restrictions on global key-sniffing by delegating hotkey management to the Desktop Environment.\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant OS as OS Hotkey Daemon\n    participant CLI as omega13 --toggle\n    participant App as Omega13App (Running)\n    participant Engine as AudioEngine\n\n    User->>OS: Press Ctrl+Alt+Space\n    OS->>CLI: Execute command\n    CLI->>App: Read PID & Send Signal\n    App->>Engine: Toggle Recording State\n    alt Start Recording\n        Engine->>Engine: Flush Ring Buffer to Disk\n    else Stop Recording\n        Engine->>App: Finalize .wav File\n        App->>App: Trigger Transcription\n    end\n```\nSources: [src/omega13/app.py:#L175-L200](), [README.md:#L60-L75]()\n\n## 5. Transcription and Data Flow\nTranscription is an asynchronous process. When a recording ends, the file path is passed to the `TranscriptionService`. A fucking weird but functional deduplication logic exists in the session management: it compares new transcription segments against the last five entries to prevent overlapping text if the engine captures redundant audio.\n\n### Transcription Logic Invariants\n- **Cooperative Shutdown:** The service uses a `threading.Event` to ensure threads are not abandoned during app exit.\n- **Deduplication:** The system joins the last 5 transcriptions (~500 words) to find the longest matching suffix with the new segment's prefix.\n- **Clipboard Integration:** If enabled in `config.json`, the result is automatically pushed to the system clipboard.\n\nSources: [src/omega13/transcription.py:#L66-L85](), [src/omega13/session.py:#L1-L30](), [src/omega13/config.py:#L40-L45]()\n\n## Conclusion\n\"Getting Started\" with Omega-13 involves a multi-stage orchestration of JACK audio, system-level signal handling, and HTTP-based inference. The architecture is structurally dependent on external components (JACK and Whisper-Server) being pre-configured, while providing a TUI that acts as the central state coordinator. The most significant structural mechanism is the retroactive ring buffer, which ensures that the 13 seconds of audio preceding a user's manual trigger are never lost.\n",
      "filePaths": [
        "bootstrap.sh",
        "README.md",
        "pyproject.toml"
      ],
      "importance": "high",
      "relatedPages": [
        "whisper-server-deployment"
      ]
    },
    {
      "id": "core-architecture",
      "title": "Core Architecture Overview",
      "content": "<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n- [src/omega13/app.py](https://github.com/b08x/omega-13/blob/main/src/omega13/app.py)\n- [src/omega13/audio.py](https://github.com/b08x/omega-13/blob/main/src/omega13/audio.py)\n- [src/omega13/session.py](https://github.com/b08x/omega-13/blob/main/src/omega13/session.py)\n- [src/omega13/config.py](https://github.com/b08x/omega-13/blob/main/src/omega13/config.py)\n- [src/omega13/transcription.py](https://github.com/b08x/omega-13/blob/main/src/omega13/transcription.py)\n- [src/omega13/ui.py](https://github.com/b08x/omega-13/blob/main/src/omega13/ui.py)\n</details>\n\n# Core Architecture Overview\n\n## Introduction\nOmega-13 is a retroactive audio recording system designed to capture audio from the past using a rolling ring buffer. The architecture is built around a central `Omega13App` that coordinates a real-time JACK-based audio engine, a session management system for data persistence, and an asynchronous transcription service. The system's primary mechanism is the continuous maintenance of a 13-second audio buffer that can be \"captured\" and persisted to disk upon user trigger, followed by automated transcription via an external HTTP API.\n\n## System Components and Responsibilities\n\nThe system is partitioned into several distinct modules that handle specific domains of the recording and processing lifecycle.\n\n| Component | Responsibility | Key Classes/Mechanisms |\n| :--- | :--- | :--- |\n| **Application Controller** | Orchestrates UI, hotkeys, and component lifecycles. | `Omega13App` |\n| **Audio Engine** | Manages JACK client, ring buffer, and WAV writing. | `AudioEngine` |\n| **Session Manager** | Handles temporary storage, metadata, and permanent saves. | `SessionManager`, `Session` |\n| **Configuration** | Persistent JSON-based settings management. | `ConfigManager` |\n| **Transcription** | Asynchronous HTTP interface to Whisper server. | `TranscriptionService` |\n| **UI Layer** | TUI implementation using the Textual framework. | `VUMeter`, `TranscriptionDisplay` |\n\nSources: [src/omega13/app.py](), [src/omega13/audio.py](), [src/omega13/session.py](), [src/omega13/config.py]()\n\n## Audio Processing and Ring Buffer Mechanism\n\nThe `AudioEngine` maintains a constant connection to the JACK audio server. It utilizes a NumPy-backed ring buffer to store incoming audio samples.\n\n### Buffer Dynamics\n- **Duration**: Fixed at 13 seconds by default.\n- **Data Structure**: A NumPy array of shape `(ring_size, channels)`.\n- **Write Pointer**: A `write_ptr` that wraps around using modulo arithmetic to maintain the rolling window.\n\nWhen a recording is triggered, the engine stitches the \"past\" (the current state of the ring buffer) with the \"present\" (incoming audio frames) until the user stops the capture. This creates a seamless transition from retroactive to proactive recording.\n\nSources: [src/omega13/audio.py:#L17-L45]()\n\n### Data Flow: Capture to Disk\nThe following diagram illustrates the flow of audio data from the JACK ports into the ring buffer and eventually to a file.\n\n```mermaid\ngraph TD\n    JACK[JACK Input Ports] -->|PCM Frames| RB[Ring Buffer - NumPy]\n    RB -->|On Capture Trigger| STITCH[Stitcher Logic]\n    STITCH -->|WAV Data| Q[Record Queue]\n    Q -->|Writer Thread| SF[SoundFile .wav]\n    SF -->|Path| SM[Session Manager]\n```\n\nSources: [src/omega13/audio.py:#L47-L65]()\n\n## Session Lifecycle and Persistence\n\nThe system uses a two-stage persistence model. Recordings are initially stored in a volatile temporary directory (typically `/tmp/omega13`) and are only moved to a permanent location if the user explicitly saves the session.\n\n### Session Structure\nA session consists of:\n1. **Recordings**: Individual `.wav` files.\n2. **Transcriptions**: Textual output from the transcription service.\n3. **Metadata**: A `session.json` file tracking IDs, timestamps, and file relationships.\n\nSources: [src/omega13/session.py:#L66-L85]()\n\n### Inconsistency: The \"Saved\" State Paradox\nA structural oddity exists in `session.py`: the `_sync_to_save_location` method is called every time a recording or transcription is added, but it only performs operations if `self.saved` is true. This means the system spends CPU cycles checking a state that is essentially a \"no-op\" for the majority of a session's early life. It's a fucking tedious way to handle incremental updates, ensuring the logic is always \"ready\" even when there's nowhere to go.\n\nSources: [src/omega13/session.py:#L45-L60]()\n\n## Transcription Integration\n\nThe `TranscriptionService` operates as a client to an external `whisper-server`. It manages a pool of threads to ensure UI responsiveness during long-running inference tasks.\n\n### Transcription Sequence\nThe interaction between the UI, the service, and the external server follows a strict request-response pattern over HTTP.\n\n```mermaid\nsequenceDiagram\n    participant UI as TranscriptionDisplay\n    participant TS as TranscriptionService\n    participant WS as Whisper Server (HTTP)\n    \n    UI->>TS: transcribe_file(path)\n    activate TS\n    TS->>TS: _check_server_health()\n    TS->>WS: POST /inference (Multipart Audio)\n    activate WS\n    WS-->>TS: 200 OK (JSON Result)\n    deactivate WS\n    TS-->>UI: TranscriptionResult (Text/Segments)\n    deactivate TS\n    UI->>UI: Update RichLog & Clipboard\n```\n\nSources: [src/omega13/transcription.py:#L45-L85](), [src/omega13/ui.py:#L55-L75]()\n\n## Configuration and Environment\n\nThe `ConfigManager` centralizes system settings, including the global hotkey and transcription server URL.\n\n| Field | Default Value | Purpose |\n| :--- | :--- | :--- |\n| `version` | 2 | Schema versioning. |\n| `global_hotkey` | `<ctrl>+<alt>+space` | System-wide trigger for capture. |\n| `save_path` | `Path.cwd()` | Default permanent storage. |\n| `transcription.server_url` | `http://localhost:8080` | Endpoint for the inference server. |\n\nSources: [src/omega13/config.py:#L26-L40]()\n\n## Conclusion\nThe core architecture of Omega-13 is a specialized pipeline designed for low-latency audio capture and high-latency text processing. The structural dependence on external components (JACK for audio and a separate HTTP server for transcription) creates a modular but fragile ecosystem where the `Omega13App` acts as the primary glue. The session management's reliance on a manual \"save\" step provides a buffer against disk clutter but introduces a layer of state management complexity where data exists in a \"limbo\" state until explicitly promoted.",
      "filePaths": [
        "src/omega13/app.py",
        "CLAUDE.md"
      ],
      "importance": "high",
      "relatedPages": [
        "audio-engine-design",
        "transcription-service"
      ]
    },
    {
      "id": "audio-engine-design",
      "title": "Audio Engine & Ring Buffers",
      "content": "<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n- [src/omega13/audio.py](https://github.com/b08x/omega-13/blob/main/src/omega13/audio.py)\n- [src/omega13/app.py](https://github.com/b08x/omega-13/blob/main/src/omega13/app.py)\n- [src/omega13/ui.py](https://github.com/b08x/omega-13/blob/main/src/omega13/ui.py)\n- [src/omega13/session.py](https://github.com/b08x/omega-13/blob/main/src/omega13/session.py)\n- [src/omega13/transcription.py](https://github.com/b08x/omega-13/blob/main/src/omega13/transcription.py)\n- [README.md](https://github.com/b08x/omega-13/blob/main/README.md)\n</details>\n\n# Audio Engine & Ring Buffers\n\n## Introduction\nThe Audio Engine and Ring Buffer system in Omega-13 functions as a retroactive capture mechanism. It maintains a continuous, rolling window of audio data in memory, allowing the system to \"go back in time\" and save audio that occurred before the user initiated a recording. This is achieved through a `jack` client integration that feeds a fixed-size NumPy array, serving as a circular buffer.\n\nSources: [src/omega13/audio.py:#L17-L45](), [README.md]()\n\n## Architecture and Data Flow\nThe system relies on the JACK (or PipeWire-JACK) audio server to provide low-latency audio streams. The `AudioEngine` class manages the lifecycle of the JACK client, port registration, and the internal state of the ring buffer.\n\n### Ring Buffer Mechanism\nThe ring buffer is implemented as a 2D NumPy array of type `float32`. The size is determined by the `BUFFER_DURATION` (defaulting to 13 seconds) multiplied by the sample rate. A `write_ptr` tracks the current position, wrapping around to zero when the end of the array is reached.\n\n```mermaid\ngraph TD\n    JACK[JACK Audio Server] -->|PCM Data| AE[AudioEngine]\n    AE -->|process| RB[Ring Buffer NumPy Array]\n    RB -->|write_ptr wrap| RB\n    AE -->|start_recording| FT[File Writer Thread]\n    FT -->|past_data + queue| SF[SoundFile .wav]\n```\n\nThe data flow ensures that even if the application is idle, the last 13 seconds of audio are always available in RAM. When a recording is triggered, the engine \"stitches\" the historical data from the ring buffer with incoming real-time data.\n\nSources: [src/omega13/audio.py:#L36-L45](), [src/omega13/audio.py:#L66-L81]()\n\n### Recording and Threading\nRecording is handled asynchronously to prevent blocking the audio processing callback. When `start_recording` is called, the engine reconstructs the buffer by concatenating the \"old\" part (from the pointer to the end) and the \"new\" part (from the start to the pointer).\n\nSources: [src/omega13/audio.py:#L109-L135]()\n\n## Component Responsibilities\n\n| Component | Responsibility | Key Attributes/Methods |\n| :--- | :--- | :--- |\n| `AudioEngine` | Manages JACK client, ring buffer state, and recording threads. | `buffer_duration`, `ring_buffer`, `process()` |\n| `VUMeter` | Reactive UI component for displaying real-time peak and dB levels. | `level`, `db_level`, `watch_level()` |\n| `SessionManager` | Manages temporary storage and metadata for recorded segments. | `create_session()`, `cleanup_old_sessions()` |\n| `Session` | Represents a single recording event with audio and transcriptions. | `recordings_dir`, `add_transcription()` |\n\nSources: [src/omega13/audio.py:#L17-L45](), [src/omega13/ui.py:#L13-L33](), [src/omega13/session.py:#L28-L50]()\n\n## Implementation Details\n\n### Buffer Reconstruction Logic\nThe logic for capturing the \"past\" depends on whether the buffer has been completely filled at least once (`buffer_filled`). If it has, the engine must perform a wrap-around slice.\n\n```python\n# src/omega13/audio.py:L117-L123\nif self.buffer_filled:\n    part_old = self.ring_buffer[self.write_ptr:]\n    part_new = self.ring_buffer[:self.write_ptr]\n    past_data = np.concatenate((part_old, part_new))\nelse:\n    past_data = self.ring_buffer[:self.write_ptr].copy()\n```\n\n### Metering and Audio Activity\nThe system calculates peak levels and decibels during the `process` loop. Interestingly, the system includes a \"Capture Blocked\" check in the `Omega13App` that prevents recording if no audio activity is detected, effectively making the engine dependent on signal presence to function.\n\nSources: [src/omega13/audio.py:#L56-L57](), [src/omega13/app.py:#L190-L205]()\n\n## Interaction Sequence: Recording Trigger\nThe following sequence illustrates the interaction between the UI, the Session Manager, and the Audio Engine when a recording is initiated.\n\n```mermaid\nsequenceDiagram\n    participant UI as Omega13App\n    participant SM as SessionManager\n    participant AE as AudioEngine\n    participant FW as File Writer Thread\n\n    UI->>AE: has_audio_activity()\n    AE-->>UI: True\n    UI->>SM: get_current_session()\n    SM-->>UI: Session Object\n    UI->>AE: start_recording(output_path)\n    activate AE\n    AE->>AE: Reconstruct past_data from ring_buffer\n    AE->>FW: Start Thread(target=_file_writer, args=past_data)\n    deactivate AE\n    FW->>FW: Write past_data to disk\n    FW->>FW: Write incoming queue to disk\n```\n\nSources: [src/omega13/app.py:#L190-L210](), [src/omega13/audio.py:#L109-L135]()\n\n## Structural Observations\nThe system exhibits a strict dependency on the JACK/PipeWire environment. While the `AudioEngine` is technically a standalone manager, it is initialized within the `Omega13App` with parameters derived from `ConfigManager`, tying the hardware interface directly to the application's configuration state. \n\nA notable architectural quirk is the `has_audio_activity` check. The application refuses to start a recording if the input signal is too low, which is a goddamn annoying way to prevent empty files but forces the user to verify their JACK routing before the \"retroactive\" feature can even be utilized. If you haven't routed your mic, the 13 seconds of \"past\" audio are effectively discarded because the engine won't commit them to disk.\n\nSources: [src/omega13/app.py:#L90-L105](), [src/omega13/app.py:#L190-L195]()\n\n## Conclusion\nThe Audio Engine and Ring Buffer system provides the core \"Time Machine\" functionality of Omega-13. By leveraging NumPy for efficient circular buffering and JACK for low-latency input, the system maintains a constant 13-second memory of audio. Its structural significance lies in its ability to decouple audio capture from file I/O through threading, though it remains functionally tethered to real-time signal detection and specific session management protocols.",
      "filePaths": [
        "src/omega13/audio.py"
      ],
      "importance": "high",
      "relatedPages": [
        "retroactive-recording"
      ]
    },
    {
      "id": "recording-lifecycle",
      "title": "Recording State Machine",
      "content": "<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n- [src/omega13/app.py](https://github.com/b08x/omega-13/blob/main/src/omega13/app.py)\n- [src/omega13/audio.py](https://github.com/b08x/omega-13/blob/main/src/omega13/audio.py)\n- [src/omega13/session.py](https://github.com/b08x/omega-13/blob/main/src/omega13/session.py)\n- [CHANGELOG.md](https://github.com/b08x/omega-13/blob/main/CHANGELOG.md)\n- [README.md](https://github.com/b08x/omega-13/blob/main/README.md)\n- [tests/test_incremental_save.py](https://github.com/b08x/omega-13/blob/main/tests/test_incremental_save.py)\n</details>\n\n# Recording State Machine\n\n## Introduction\nThe Recording State Machine in Omega-13 coordinates the transition between passive audio buffering (retroactive capture) and active file writing. It operates as a bridge between a JACK-based `AudioEngine`, which maintains a 13-second rolling ring buffer, and a `SessionManager` that handles the persistence of these captures. The system's primary role is to ensure that when a recording is triggered, the \"past\" audio stored in the ring buffer is seamlessly prepended to the \"present\" audio stream being written to disk.\n\nSources: [src/omega13/audio.py:#L21-L40](), [README.md:#L63-L67]()\n\n## Architectural Overview and Data Flow\nThe system utilizes a multi-threaded architecture to prevent UI blocking during high-latency I/O operations. The `Omega13App` (the TUI) acts as the primary controller, reacting to hotkeys or UI events to signal the `AudioEngine`.\n\n### Buffer Reconstruction Mechanism\nA critical structural aspect of the state machine is how it handles the transition from buffering to recording. The `AudioEngine` maintains a `ring_buffer` of a fixed `BUFFER_DURATION` (default 13 seconds). Upon a start signal, the engine reconstructs the audio timeline by concatenating the \"old\" part of the buffer (from the current write pointer to the end) with the \"new\" part (from the start to the pointer).\n\n```python\n# src/omega13/audio.py\nif self.buffer_filled:\n    part_old = self.ring_buffer[self.write_ptr:]\n    part_new = self.ring_buffer[:self.write_ptr]\n    past_data = np.concatenate((part_old, part_new))\nelse:\n    past_data = self.ring_buffer[:self.write_ptr].copy()\n```\nSources: [src/omega13/audio.py:#L18-L35]()\n\n### State Transitions\nThe recording state is managed via the `is_recording` boolean flag within the `AudioEngine`. This flag acts as a primitive mutex, preventing concurrent recording sessions. Interestingly, the system relies on a `stop_event` (a `threading.Event`) to coordinate the termination of the `writer_thread`, which is responsible for flushing the `record_queue` to a `.wav` file.\n\nSources: [src/omega13/audio.py:#L56-L70](), [src/omega13/app.py:#L221-L235]()\n\n## Component Interactions\n\nThe following sequence diagram illustrates the interaction between the TUI, the Audio Engine, and the Session Management during a capture event.\n\n```mermaid\nsequenceDiagram\n    participant U as User/Hotkey\n    participant A as Omega13App\n    participant E as AudioEngine\n    participant S as Session\n    participant W as WriterThread\n\n    U->>A: Trigger Hotkey (REC)\n    A->>E: start_recording(path)\n    activate E\n    E->>E: Reconstruct Ring Buffer\n    E->>W: Start Thread(past_data)\n    activate W\n    E-->>A: Return Path\n    deactivate E\n    A->>S: get_next_recording_path()\n    A->>A: Update UI (Status: RECORDING)\n    \n    U->>A: Trigger Hotkey (STOP)\n    A->>E: stop_recording()\n    E->>W: Set stop_event\n    W->>W: Flush remaining queue\n    W-->>E: Thread Exit\n    deactivate W\n    A->>S: register_recording(filepath)\n```\n\nSources: [src/omega13/app.py:#L221-L245](), [src/omega13/audio.py:#L1-L40](), [src/omega13/session.py:#L110-L125]()\n\n## State and Configuration Attributes\n\n| Component | Attribute | Role |\n| :--- | :--- | :--- |\n| `AudioEngine` | `is_recording` | Boolean flag indicating active file I/O. |\n| `AudioEngine` | `ring_size` | Calculated as `samplerate * buffer_duration`. |\n| `AudioEngine` | `record_queue` | Thread-safe queue for real-time JACK samples. |\n| `Session` | `recordings_dir` | Path where `.wav` files are temporarily stored. |\n| `Omega13App` | `_shutdown_initiated` | Prevents signal-handling loops during exit. |\n\nSources: [src/omega13/audio.py:#L55-L65](), [src/omega13/session.py:#L88-L95](), [src/omega13/app.py:#L105-L110]()\n\n## Observed Structural Patterns and Contradictions\n\n### The \"Session\" Persistence Gap\nThe system exhibits a somewhat contradictory approach to data safety. While it meticulously maintains a 13-second safety net in RAM, the actual persistence to a user-defined directory is entirely manual. A session is created in a temporary directory (`/tmp/omega13` or similar) and is only \"saved\" (moved to permanent storage) if the user explicitly triggers the `save_session` command. If the application crashes or the user forgets to press `S`, the \"captured\" recordings remain in temporary storage, effectively making the \"permanent\" capture ephemeral by default.\n\nSources: [src/omega13/session.py:#L175-L195](), [README.md:#L45-L50]()\n\n### Incremental Syncing Logic\nThe `Session` class implements an `_sync_to_save_location` method that is called every time a recording is registered or a transcription is added. However, this sync only executes if `self.saved` is true. This creates a state where the system performs \"incremental saves\" for an already saved session, but offers no background protection for unsaved ones. It's a \"lock the door only after the guest has already moved in\" architectural pattern.\n\nSources: [src/omega13/session.py:#L177-L185](), [tests/test_incremental_save.py:#L30-L45]()\n\n## Conclusion\nThe Recording State Machine is a high-performance audio capture mechanism that prioritizes low-latency buffer reconstruction over immediate data persistence. Its structural integrity relies on the synchronization between the JACK process callback (filling the ring buffer) and the `AudioEngine`'s writer thread. While robust in its audio handling, the system's reliance on manual session promotion introduces a functional dependency on user intervention for long-term data retention.\n\nSources: [src/omega13/audio.py](), [src/omega13/app.py]()",
      "filePaths": [
        "src/omega13/recording_controller.py"
      ],
      "importance": "medium",
      "relatedPages": [
        "voice-activity-detection"
      ]
    },
    {
      "id": "retroactive-recording",
      "title": "Retroactive Recording Mechanism",
      "content": "<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n- [src/omega13/audio.py](https://github.com/b08x/omega-13/blob/main/src/omega13/audio.py)\n- [src/omega13/app.py](https://github.com/b08x/omega-13/blob/main/src/omega13/app.py)\n- [src/omega13/session.py](https://github.com/b08x/omega-13/blob/main/src/omega13/session.py)\n- [src/omega13/ui.py](https://github.com/b08x/omega-13/blob/main/src/omega13/ui.py)\n- [README.md](https://github.com/b08x/omega-13/blob/main/README.md)\n- [CHANGELOG.md](https://github.com/b08x/omega-13/blob/main/CHANGELOG.md)\n</details>\n\n# Retroactive Recording Mechanism\n\n### 1. Introduction\nThe Retroactive Recording Mechanism in Omega-13 is a continuous audio buffering system designed to capture audio data that occurred *prior* to a user's explicit trigger. By maintaining a rolling 13-second ring buffer in memory, the system allows for \"time-rewind\" capabilities where a capture event persists both the historical buffer and the live incoming stream to a physical file.\n\nSources: [README.md](), [src/omega13/audio.py:#L14-L15]()\n\n### 2. Core Architecture and Data Flow\n\n#### 2.1 The Rolling Ring Buffer\nThe system's heart is a NumPy-based ring buffer initialized within the `AudioEngine`. This buffer is statically sized based on the sample rate and a fixed 13-second duration.\n\n- **Initialization**: The buffer is a `float32` array with dimensions `(samplerate * 13, channels)`.\n- **Continuous Write**: A `write_ptr` tracks the current position. When the pointer reaches the end of the array, it wraps back to zero, overwriting the oldest data.\n- **State Tracking**: A `buffer_filled` flag is set once the pointer has completed its first full pass, indicating that a full 13 seconds of history is available.\n\nSources: [src/omega13/audio.py:#L36-L42]()\n\n#### 2.2 Trigger and Reconstruction\nWhen a recording is triggered (via global hotkey or UI), the `AudioEngine` performs a \"buffer reconstruction.\" This process is fucking critical because it transforms a circular memory structure into a linear temporal sequence for the file writer.\n\n| Step | Action | Logic |\n| :--- | :--- | :--- |\n| 1 | **Identify Past Data** | If `buffer_filled` is true, it concatenates the segment from `write_ptr` to end with the segment from start to `write_ptr`. |\n| 2 | **Initialize Writer** | A background `writer_thread` is spawned to handle I/O without blocking the audio callback. |\n| 3 | **Live Append** | Incoming audio during the active recording phase is pushed to a `record_queue` for the writer thread to consume. |\n\nSources: [src/omega13/audio.py:#L73-L98]()\n\n### 3. System Interactions\n\nThe following sequence diagram illustrates the flow from a hotkey trigger through the audio reconstruction and eventual transcription.\n\n```mermaid\nsequenceDiagram\n    participant H as GlobalHotkeyListener\n    participant A as Omega13App\n    participant E as AudioEngine\n    participant S as SessionManager\n    participant W as WriterThread\n    participant T as TranscriptionService\n\n    H->>A: Trigger Hotkey\n    A->>E: start_recording(path)\n    activate E\n    E->>E: Reconstruct Ring Buffer\n    E-->>W: Spawn Thread (past_data)\n    W->>W: Write past_data to .wav\n    E-->>A: Return Path\n    deactivate E\n    \n    Note over A,E: User records live audio...\n    \n    H->>A: Trigger Hotkey (Stop)\n    A->>E: stop_recording()\n    E->>W: Signal Stop\n    W->>W: Flush queue & Close File\n    W-->>A: Recording Finished\n    \n    A->>S: register_recording(path)\n    A->>T: transcribe(path)\n    T-->>A: Return Text\n    A->>S: add_transcription(text)\n```\n\nSources: [src/omega13/app.py:#L12-L40](), [src/omega13/audio.py:#L73-L110](), [src/omega13/session.py:#L145-L160]()\n\n### 4. Component Responsibilities\n\nThe system relies on a tight coupling between the JACK audio server and the Python-based management logic.\n\n| Component | Responsibility | Key Interaction |\n| :--- | :--- | :--- |\n| `AudioEngine` | Buffer management and JACK I/O. | Uses `numpy` for high-speed buffer rotation. |\n| `Session` | File path generation and metadata. | Generates sequential filenames like `001.wav`. |\n| `WriterThread` | Non-blocking Disk I/O. | Consumes `record_queue` to prevent audio dropouts. |\n| `Omega13App` | State coordination. | Orchestrates the transition from recording to transcription. |\n\nSources: [src/omega13/audio.py:#L17-L55](), [src/omega13/session.py:#L120-L140](), [src/omega13/app.py]()\n\n### 5. Observed Structural Tendencies\nAn interesting, albeit somewhat rigid, pattern is the hardcoding of the `BUFFER_DURATION` to 13 seconds in `audio.py`. While the `AudioEngine` accepts a `buffer_duration` argument, the constant `BUFFER_DURATION = 13` is the system default, deeply tying the application's identity (Omega-13) to its technical implementation.\n\nFurthermore, the \"Capture Blocked\" logic mentioned in the README implies a dependency on signal detection. If the input signal is silent, the system may refuse to persist the buffer, an implicit constraint that ensures the \"time machine\" doesn't waste resources on silence.\n\nSources: [src/omega13/audio.py:#L14](), [README.md: \"Troubleshooting\"]()\n\n### 6. Conclusion\nThe Retroactive Recording Mechanism is a specialized implementation of a circular buffer that leverages NumPy for performance and JACK for low-latency audio access. Its structural significance lies in the seamless transition between asynchronous memory buffering and synchronous file persistence, mediated by a dedicated writer thread to ensure system stability during I/O-heavy operations.\n\nSources: [src/omega13/audio.py](), [src/omega13/session.py]()",
      "filePaths": [
        "src/omega13/audio.py"
      ],
      "importance": "high",
      "relatedPages": [
        "audio-engine-design"
      ]
    },
    {
      "id": "voice-activity-detection",
      "title": "Voice-Activated Auto-Record (VAD)",
      "content": "<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n- [src/omega13/app.py](https://github.com/b08x/omega-13/blob/main/src/omega13/app.py)\n- [src/omega13/audio.py](https://github.com/b08x/omega-13/blob/main/src/omega13/audio.py)\n- [src/omega13/session.py](https://github.com/b08x/omega-13/blob/main/src/omega13/session.py)\n- [src/omega13/transcription.py](https://github.com/b08x/omega-13/blob/main/src/omega13/transcription.py)\n- [src/omega13/ui.py](https://github.com/b08x/omega-13/blob/main/src/omega13/ui.py)\n- [CHANGELOG.md](https://github.com/b08x/omega-13/blob/main/CHANGELOG.md)\n</details>\n\n# Voice-Activated Auto-Record (VAD)\n\n## 1. Introduction\nVoice-Activated Auto-Record (VAD), referred to in the codebase as \"pre-recording audio activity detection,\" is a mechanism designed to gate the recording process based on the presence of audio signals. Its primary role is to prevent the system from capturing and processing silent or empty audio buffers, which would otherwise waste computational resources during the transcription phase. The system operates by monitoring input levels and blocking capture triggers if the signal does not meet specific activity thresholds.\n\nSources: [CHANGELOG.md](), [README.md]()\n\n## 2. Audio Monitoring and Signal Detection\nThe VAD mechanism is integrated into the `AudioEngine` and the UI's `VUMeter` components. The system calculates decibel (dB) levels and peak amplitudes from the JACK input ports to determine if a \"thought\" is actually being spoken.\n\n### 2.1 Metering and Thresholds\nThe `AudioEngine` maintains real-time peak and dB calculations for each input channel. These values are used by the UI to provide visual feedback and by the recording logic to validate if a capture should proceed.\n\n| Component | Responsibility | Data Points |\n| :--- | :--- | :--- |\n| `AudioEngine` | Real-time signal processing | `self.peaks`, `self.dbs` |\n| `VUMeter` | Visual representation of signal | `level`, `db_level` |\n| `TranscriptionService` | Post-capture validation | Audio path existence/validity |\n\nSources: [src/omega13/audio.py:#L46-L47](), [src/omega13/ui.py:#L14-L32]()\n\n### 2.2 Structural Flow of Signal Validation\nThe system utilizes a rolling NumPy ring buffer to store the last 13 seconds of audio. When a capture is triggered (via global hotkey or CLI), the system checks the buffer state. If no signal is detected\u2014a state described in the documentation as \"Capture Blocked - No Input Signal\"\u2014the recording process is aborted.\n\n```mermaid\ngraph TD\n    A[Global Hotkey Trigger] --> B{Signal Detected?}\n    B -- No --> C[Block Capture / Notify User]\n    B -- Yes --> D[Stitch Ring Buffer]\n    D --> E[Write .wav to Session]\n    E --> F[Initiate Transcription]\n```\nNote: The \"Capture Blocked\" state is an explicit safety check to ensure the local AI model (Whisper) is not invoked on silence.\n\nSources: [src/omega13/audio.py:#L66-L95](), [README.md]()\n\n## 3. Implementation Details\n\n### 3.1 Buffer Management\nThe `AudioEngine` handles the 13-second \"retroactive\" window. The VAD logic implicitly relies on the `buffer_filled` flag and the `write_ptr` to determine if there is sufficient data to even evaluate for activity.\n\n```python\n# src/omega13/audio.py:#L79-L85\nif self.buffer_filled:\n    part_old = self.ring_buffer[self.write_ptr:]\n    part_new = self.ring_buffer[:self.write_ptr]\n    past_data = np.concatenate((part_old, part_new))\nelse:\n    past_data = self.ring_buffer[:self.write_ptr].copy()\n```\n\nSources: [src/omega13/audio.py:#L79-L85]()\n\n### 3.2 Integration with UI\nThe `Omega13App` coordinates the VAD feedback loop. If the `AudioEngine` reports peaks below the threshold, the `status-bar` in the TUI remains `IDLE` or displays a warning, preventing the transition to the `RECORDING` state (marked by a red UI change).\n\nSources: [src/omega13/app.py:#L45-L55](), [src/omega13/app.py:#L174-L185]()\n\n## 4. Observed Structural Inconsistencies\nThe system presents a curious contradiction in its \"always listening\" philosophy. While it maintains a constant 13-second buffer, the actual VAD logic appears to be a \"gatekeeper\" at the moment of trigger rather than a continuous start/stop mechanism. This means the system is fucking listening all the time, but it only decides if that listening was \"worth it\" once you've already hit the button. \n\nFurthermore, the `TranscriptionService` is strictly dependent on the output of this gated recording. If the VAD logic fails to block a silent recording, the system will proceed to send an empty `.wav` file to the `whisper-server`, leading to unnecessary HTTP overhead and potential \"processing\" of background noise.\n\nSources: [src/omega13/transcription.py:#L57-L70](), [README.md]()\n\n## 5. Conclusion\nThe Voice-Activated Auto-Record (VAD) mechanism in Omega-13 serves as a critical filter between the continuous audio capture of the JACK client and the resource-heavy AI transcription backend. By leveraging real-time peak detection and decibel monitoring, it ensures that only meaningful audio segments are promoted from the temporary ring buffer to permanent session storage. Its structural significance lies in its role as a resource-saver for local GPU/CPU inference.",
      "filePaths": [
        "src/omega13/signal_detector.py"
      ],
      "importance": "medium",
      "relatedPages": [
        "recording-lifecycle"
      ]
    },
    {
      "id": "transcription-service",
      "title": "Transcription & Whisper Integration",
      "content": "<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n- [src/omega13/transcription.py](https://github.com/b08x/omega-13/blob/main/src/omega13/transcription.py)\n- [src/omega13/app.py](https://github.com/b08x/omega-13/blob/main/src/omega13/app.py)\n- [src/omega13/session.py](https://github.com/b08x/omega-13/blob/main/src/omega13/session.py)\n- [src/omega13/config.py](https://github.com/b08x/omega-13/blob/main/src/omega13/config.py)\n- [README.md](https://github.com/b08x/omega-13/blob/main/README.md)\n- [src/omega13/ui.py](https://github.com/b08x/omega-13/blob/main/src/omega13/ui.py)\n</details>\n\n# Transcription & Whisper Integration\n\nThe transcription system in Omega-13 functions as a decoupled, asynchronous pipeline that bridges local audio capture with an externalized AI inference engine. It relies on a containerized `whisper-server` communicating via an HTTP API to transform `.wav` recordings into text, which is then processed for deduplication and session persistence.\n\n## 1. System Architecture and Data Flow\n\nThe integration is built around the `TranscriptionService` class, which manages the lifecycle of transcription requests. The flow begins when the `Omega13App` triggers a recording stop, resulting in a saved audio file that is then dispatched to the service.\n\n### Transcription Pipeline Flow\nThe following diagram illustrates the sequence from audio finalization to text delivery.\n\n```mermaid\nsequenceDiagram\n    participant App as Omega13App\n    participant TS as TranscriptionService\n    participant WS as Whisper Server (Docker)\n    participant SM as SessionManager\n    participant CB as Clipboard\n\n    App->+TS: transcribe_async(audio_path, callback)\n    TS->+WS: HTTP POST /inference (audio file)\n    Note over WS: CUDA-accelerated processing\n    WS-->>-TS: JSON Response {text, language}\n    TS->+SM: add_transcription(text)\n    Note over SM: Word-based deduplication\n    SM-->>-TS: Updated Session\n    TS->+CB: copy_to_clipboard(text)\n    Note over CB: If enabled in config\n    TS-->>-App: Invoke callback(TranscriptionResult)\n```\nSources: `[src/omega13/transcription.py:#L83-L110]`, `[src/omega13/app.py:#L145-L160]`, `[README.md]`\n\n## 2. Core Components and Mechanisms\n\n### TranscriptionService\nThis class encapsulates the HTTP logic and threading required to interact with the Whisper backend. It uses a `threading.Thread` with `daemon=False` to ensure that transcription tasks are not abruptly killed during application exit, though it implements a `_shutdown_event` for cooperative termination.\n\n**Key Attributes:**\n| Attribute | Description | Source |\n| :--- | :--- | :--- |\n| `server_url` | Base URL for the whisper-server (default: `http://localhost:8080`) | `[src/omega13/transcription.py:#L36]` |\n| `endpoint` | Concatenation of URL and `/inference` path | `[src/omega13/transcription.py:#L43]` |\n| `timeout` | 600-second limit for inference requests | `[src/omega13/transcription.py:#L38]` |\n\n### Data Structures\nThe system utilizes a `TranscriptionResult` dataclass to pass structured information back to the UI.\n```python\n@dataclass\nclass TranscriptionResult:\n    text: str\n    status: TranscriptionStatus\n    error: Optional[str] = None\n    segments: Optional[list[dict]] = None\n    language: Optional[str] = None\n    duration: Optional[float] = None\n```\nSources: `[src/omega13/transcription.py:#L24-L31]`\n\n## 3. Session Integration and Deduplication\n\nA critical, albeit slightly annoying, architectural detail is how the system handles overlapping audio. Since Omega-13 captures \"13 seconds before\" the trigger, consecutive recordings often contain redundant speech. The `Session` class in `session.py` attempts to fix this shit by performing word-based suffix-prefix matching.\n\n### Deduplication Logic\nThe `add_transcription` method compares the new text against the last five entries in the session history. It identifies the longest overlapping word sequence and strips it from the new segment before saving.\n\n```python\nhistory_context = \" \".join(self.transcriptions[-5:]).split()\nnew_words = new_text.split()\n\n# Find the longest suffix of history that matches the prefix of new_words\nmax_overlap = 0\nfor i in range(1, min(len(history_context), len(new_words)) + 1):\n    if history_context[-i:] == new_words[:i]:\n        max_overlap = i\n\nunique_segment = \" \".join(new_words[max_overlap:])\n```\nSources: `[src/omega13/session.py:#L22-L55]`\n\n## 4. Configuration and Environment\n\nThe transcription behavior is governed by the `ConfigManager`. While the system defaults to a local server, it is hardcoded to expect specific response keys like `text`.\n\n| Config Field | Default Value | Description |\n| :--- | :--- | :--- |\n| `enabled` | `True` | Global toggle for transcription |\n| `server_url` | `http://localhost:8080` | Endpoint for the Docker container |\n| `model_size` | `large-v3-turbo` | The specific Whisper model requested |\n| `copy_to_clipboard` | `False` (UI Toggle) | Automatic sync to system clipboard |\n\nSources: `[src/omega13/config.py:#L32-L40]`, `[src/omega13/app.py:#L100]`\n\n## 5. Structural Observations and Contradictions\n\nThe architecture presents a few interesting operational tendencies:\n- **Dependency Paradox:** The application is designed as a TUI, yet it is functionally useless for its primary purpose without a heavy Docker-based CUDA backend. If the `whisper-server` is down, the `TranscriptionService` returns an `ERROR` status, but the audio is still saved to the session, creating a \"silent\" session metadata file.\n- **Thread Management:** The switch from `daemon=True` to `daemon=False` in `transcribe_async` indicates a move toward \"cooperative shutdown.\" However, the code still uses a `_shutdown_event` that requires the worker thread to check it manually, which could still lead to hangs if the `requests.post` call is blocked mid-inference.\n- **Deduplication Sensitivity:** The deduplication relies entirely on exact word matches. Any slight variation in Whisper's output for the same audio (due to hallucinations or temperature) will cause the deduplication to fail, resulting in stuttered text in the final session file.\n\nSources: `[src/omega13/transcription.py:#L107]`, `[src/omega13/session.py:#L45]`, `[CHANGELOG.md]`\n\n## Conclusion\n\nThe Transcription & Whisper Integration is the primary data-consumer of the Omega-13 system. It transforms transient audio buffers into persistent, deduplicated text through an asynchronous HTTP-based bridge to a containerized inference engine. Its structural significance lies in its role as the final stage of the \"retroactive\" pipeline, ensuring that captured thoughts are not just recorded, but immediately actionable via the clipboard and session storage.",
      "filePaths": [
        "src/omega13/transcription.py",
        "compose.yml"
      ],
      "importance": "high",
      "relatedPages": [
        "whisper-server-deployment"
      ]
    },
    {
      "id": "tui-and-ux",
      "title": "TUI Components & UX",
      "content": "<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n- [src/omega13/ui.py](https://github.com/b08x/omega-13/blob/main/src/omega13/ui.py)\n- [src/omega13/app.py](https://github.com/b08x/omega-13/blob/main/src/omega13/app.py)\n- [src/omega13/config.py](https://github.com/b08x/omega-13/blob/main/src/omega13/config.py)\n- [src/omega13/session.py](https://github.com/b08x/omega-13/blob/main/src/omega13/session.py)\n- [README.md](https://github.com/b08x/omega-13/blob/main/README.md)\n- [CHANGELOG.md](https://github.com/b08x/omega-13/blob/main/CHANGELOG.md)\n</details>\n\n# TUI Components & UX\n\n### 1. Introduction\nThe OMEGA-13 Terminal User Interface (TUI) is built using the `Textual` framework to provide a real-time control center for retroactive audio capture and transcription. It functions as a state-driven dashboard that coordinates between the `AudioEngine` (JACK/PipeWire), the `SessionManager` (file I/O), and the `TranscriptionService` (HTTP API). The interface is structurally divided into a monitoring pane for audio levels and a log-based display for transcription results, relying on a global hotkey mechanism to bridge the gap between background operation and foreground feedback.\n\n### 2. Layout Architecture and Data Flow\nThe application uses a `Horizontal` layout split into a 40% control pane and a 60% transcription pane. The structural hierarchy is defined in `Omega13App.compose`, which yields a standard `Header`, `Footer`, and a main `Container` for the panes.\n\n#### Component Hierarchy\n- **Left Pane (`#left-pane`)**: Contains `#audio-controls` (status, session info, VU meters) and `#transcription-controls` (status label and clipboard toggle).\n- **Right Pane (`#transcription-pane`)**: Dedicated to the `TranscriptionDisplay` widget for viewing output.\n\nSources: [src/omega13/app.py:#L36-L65](), [src/omega13/app.py:#L130-L150]()\n\n#### Information Flow Mechanism\nThe TUI does not directly process audio; instead, it queries the `AudioEngine` state at regular intervals to update reactive widgets.\n\ngraph TD\n    AE[AudioEngine] -->|Peaks/dB| APP[Omega13App]\n    APP -->|Reactive Update| VU[VUMeter]\n    TS[TranscriptionService] -->|Status/Text| APP\n    APP -->|Update| TD[TranscriptionDisplay]\n    CM[ConfigManager] -->|Settings| APP\n    APP -->|Mount/Init| TD\n\nSources: [src/omega13/app.py:#L179-L195](), [src/omega13/ui.py:#L16-L40]()\n\n### 3. Core UI Components\n\n#### VUMeter\nA custom widget that visualizes audio input levels. It uses `Textual` reactive properties (`level`, `db_level`) to trigger UI updates. The bar color shifts from green to yellow to red based on the percentage of the signal, which is a fucking standard but necessary visual cue for preventing clipping.\n\n| Property | Type | Description |\n| :--- | :--- | :--- |\n| `level` | `reactive(float)` | Linear amplitude (0.0 to 1.0) |\n| `db_level` | `reactive(float)` | Logarithmic level in decibels |\n\nSources: [src/omega13/ui.py:#L16-L40]()\n\n#### TranscriptionDisplay\nThis component manages the `RichLog` where text results appear. It is tightly coupled with the app's transcription status. While it claims to be a display widget, it also holds a reference to the `clipboard-toggle` checkbox, creating a somewhat messy dependency where the UI state directly influences whether the `SessionManager` or `TranscriptionService` triggers a system clipboard event.\n\nSources: [src/omega13/ui.py:#L42-L96](), [src/omega13/app.py:#L144-L148]()\n\n### 4. User Interaction & Modal Screens\nThe UX relies on `ModalScreen` instances for configuration tasks, ensuring that the main audio processing loop is not interrupted by blocking UI calls.\n\n#### Input Selection Flow\nThe `InputSelectionScreen` allows users to toggle between Mono and Stereo modes and select JACK ports. This is a multi-step state machine within a modal.\n\nsequenceDiagram\n    participant U as User\n    participant APP as Omega13App\n    participant ISS as InputSelectionScreen\n    participant AE as AudioEngine\n\n    U->>APP: Press 'I'\n    APP->>ISS: Push Screen (available_ports)\n    ISS->>U: Show Mode Selection (Mono/Stereo)\n    U->>ISS: Select Mode\n    ISS->>U: Show Port List\n    U->>ISS: Select Port(s)\n    ISS->>APP: Dismiss with (port_tuple)\n    APP->>AE: Update Input Connections\n\nSources: [src/omega13/ui.py:#L123-L157](), [src/omega13/app.py:#L80-L85]()\n\n### 5. Interaction Hotkeys and Bindings\nThe TUI maps specific keys to system actions, which are mirrored in the footer and help text.\n\n| Key | Action | Method |\n| :--- | :--- | :--- |\n| `i` | Select Inputs | `action_open_input_selector` |\n| `s` | Save Session | `action_save_session` |\n| `t` | Manual Transcribe | `action_manual_transcribe` |\n| `q` | Quit | `action_quit` |\n\nSources: [src/omega13/app.py:#L80-L85](), [README.md:TUI Shortcuts]()\n\n### 6. Observed Structural Inconsistencies\nThe system exhibits a \"cooperative\" but potentially fragile relationship between the TUI and the background engine. For instance, the `VUMeter` visibility is toggled based on the number of channels detected in the `AudioEngine` during `_update_meter_visibility`, but the UI layout itself (`#meters` container) has a fixed height of 5 in the CSS, which may lead to layout overflow or empty space if the channel count changes dynamically.\n\nFurthermore, the `TranscriptionDisplay` queries the `status_label` and `clipboard_checkbox` from the global `app` instance during `on_mount`, rather than having them passed as parameters or managed via a formal provider pattern. This creates a hard structural link between the widget and the specific ID naming convention used in `app.py`.\n\nSources: [src/omega13/app.py:#L51-L55](), [src/omega13/ui.py:#L60-L65]()\n\n### 7. Conclusion\nThe TUI Components & UX of OMEGA-13 serve as a real-time visualization layer for a complex audio-to-text pipeline. By utilizing reactive widgets for level monitoring and modal screens for hardware configuration, the system maintains a responsive interface. However, the structural integrity relies heavily on string-based ID lookups across modules and a manual synchronization between the `AudioEngine` state and UI visibility.\n\nSources: [src/omega13/app.py](), [src/omega13/ui.py]()",
      "filePaths": [
        "src/omega13/ui.py",
        "src/omega13/app.py"
      ],
      "importance": "medium",
      "relatedPages": [
        "configuration-and-hotkeys"
      ]
    },
    {
      "id": "session-management",
      "title": "Session Management & Data Flow",
      "content": "<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n- [src/omega13/session.py](https://github.com/b08x/omega-13/blob/main/src/omega13/session.py)\n- [src/omega13/app.py](https://github.com/b08x/omega-13/blob/main/src/omega13/app.py)\n- [tests/test_incremental_save.py](https://github.com/b08x/omega-13/blob/main/tests/test_incremental_save.py)\n- [tests/test_deduplication.py](https://github.com/b08x/omega-13/blob/main/tests/test_deduplication.py)\n- [CHANGELOG.md](https://github.com/b08x/omega-13/blob/main/CHANGELOG.md)\n</details>\n\n# Session Management & Data Flow\n\n## Introduction\nThe session management system in Omega-13 coordinates the lifecycle of retroactive audio captures, metadata persistence, and transcription synchronization. It functions as a stateful bridge between volatile temporary storage (typically `/tmp/omega13`) and permanent user-defined directories. The architecture relies on a hierarchical structure where a `SessionManager` orchestrates `Session` objects, which in turn aggregate `SessionRecording` metadata and deduplicated transcription strings.\n\nSources: [src/omega13/session.py:#L1-L15](), [src/omega13/app.py:#L1-L25]()\n\n## Session Architecture and Lifecycle\nThe system enforces a strict transition from temporary \"in-flight\" data to \"saved\" permanent data. A session is initialized in a temporary root directory with a unique ID composed of a timestamp and a UUID fragment.\n\n### Component Responsibilities\n| Component | Responsibility | Key Data Structures |\n| :--- | :--- | :--- |\n| `SessionManager` | Lifecycle management: creation, retrieval, saving, and cleanup of sessions. | `current_session`, `temp_root` |\n| `Session` | Management of a specific capture event, including directory structure and metadata syncing. | `recordings`, `transcriptions`, `session_dir` |\n| `SessionRecording` | Metadata for individual audio files (WAV). | `filename`, `duration_seconds`, `timestamp` |\n\nSources: [src/omega13/session.py:#L22-L140]()\n\n### Structural Flow of Session Persistence\nThe following diagram illustrates the transition of audio data and metadata from the active recording state to permanent storage.\n\n```mermaid\ngraph TD\n    A[App Initialization] --> B[SessionManager.create_session]\n    B --> C[Session Object Created]\n    C --> D[Temporary Directory Structure]\n    D --> D1[/recordings]\n    D --> D2[/transcriptions]\n    D --> D3[session.json]\n    E[Audio Engine Capture] --> F[Session.register_recording]\n    F --> G[Update Metadata & Sync]\n    G --> H{Is Session Saved?}\n    H -- Yes --> I[shutil.copy2 to Permanent Loc]\n    H -- No --> J[Stay in Temp Root]\n```\nSources: [src/omega13/session.py:#L145-L180](), [src/omega13/app.py:#L30-L50]()\n\n## Transcription Deduplication Mechanism\nA notable, albeit somewhat finicky, feature is the word-based suffix-prefix overlap deduplication. When new transcription text is added, the system attempts to strip redundant content that may have been repeated by the transcription engine (e.g., Whisper) across overlapping audio segments.\n\nThe logic joins the last 5 transcription segments to create a `history_context` and searches for the longest matching prefix in the `new_words` list.\n\n```python\n# src/omega13/session.py\nhistory_context = \" \".join(self.transcriptions[-5:]).split()\nnew_words = new_text.split()\n\nmax_overlap = 0\nmax_search = min(len(history_context), len(new_words))\n\nfor i in range(1, max_search + 1):\n    if history_context[-i:] == new_words[:i]:\n        max_overlap = i\n```\n\nSources: [src/omega13/session.py:#L185-L210](), [tests/test_deduplication.py:#L10-L35]()\n\n## Incremental Saving and Synchronization\nThe system supports incremental saving, meaning once a session is marked as \"saved\" via `SessionManager.save_session()`, any subsequent recordings or transcriptions added to the `Session` object are automatically synchronized to the permanent location.\n\n### Observations on Synchronization Constraints\nThere is a functional dependency where `_sync_to_save_location` silently fails or returns early if `self.saved` is False. This creates a state where data is \"trapped\" in `/tmp` until the user explicitly triggers a save via the UI. If the application crashes before this trigger, the temporary data is subject to `cleanup_old_sessions` in subsequent runs, which is a cold, efficient way to lose unsaved data.\n\nSources: [src/omega13/session.py:#L215-L245](), [tests/test_incremental_save.py:#L20-L50]()\n\n## Data Interaction Sequence\nThe interaction between the UI (`Omega13App`), the `SessionManager`, and the filesystem follows a sequential pattern during a save operation.\n\n```mermaid\nsequenceDiagram\n    participant UI as Omega13App\n    participant SM as SessionManager\n    participant S as Session\n    participant FS as FileSystem\n\n    UI->+SM: save_session(destination)\n    SM->+S: Update save_location\n    S->>S: set saved = True\n    S->FS: mkdir(destination/recordings)\n    S->FS: copy2(session.json)\n    S->FS: copy2(audio_files)\n    S-->>-SM: Success\n    SM-->>-UI: True\n```\nSources: [src/omega13/app.py:#L100-L120](), [src/omega13/session.py:#L260-L290]()\n\n## Structural Significance\nThe session management logic serves as the primary state machine for Omega-13. By decoupling the `AudioEngine` from the final storage location through a temporary session directory, the system ensures that the overhead of file I/O during time-sensitive audio capture is localized to temporary storage. However, the reliance on manual save triggers to initiate the `_sync_to_save_location` mechanism introduces a rigid boundary between \"volatile\" and \"persistent\" states that the user must navigate.\n\nSources: [CHANGELOG.md](), [src/omega13/session.py]()",
      "filePaths": [
        "src/omega13/session.py",
        "tests/test_incremental_save.py"
      ],
      "importance": "medium",
      "relatedPages": [
        "recording-lifecycle"
      ]
    },
    {
      "id": "configuration-and-hotkeys",
      "title": "Configuration & Global Hotkeys",
      "content": "<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n- [src/omega13/config.py](https://github.com/b08x/omega-13/blob/main/src/omega13/config.py)\n- [src/omega13/hotkeys.py](https://github.com/b08x/omega-13/blob/main/src/omega13/hotkeys.py)\n- [src/omega13/app.py](https://github.com/b08x/omega-13/blob/main/src/omega13/app.py)\n- [README.md](https://github.com/b08x/omega-13/blob/main/README.md)\n- [CHANGELOG.md](https://github.com/b08x/omega-13/blob/main/CHANGELOG.md)\n</details>\n\n# Configuration & Global Hotkeys\n\n## Introduction\nThe configuration and global hotkey systems in Omega-13 serve as the operational backbone for retroactive audio capture. The `ConfigManager` handles persistent state and user preferences via a JSON-based schema, while the `GlobalHotkeyListener` provides a bridge between the system's input events and the application's recording logic. These components are tightly coupled with the `Omega13App` lifecycle, ensuring that user-defined shortcuts and environmental settings (like JACK/PipeWire ports) are synchronized with the hardware abstraction layer.\n\n## Configuration Management\nThe `ConfigManager` class handles the serialization and deserialization of application settings stored at `~/.config/omega13/config.json`. It provides a centralized API for accessing audio paths, transcription server URLs, and hotkey strings.\n\n### Key Configuration Schema\nThe configuration is structured into top-level keys and nested objects for specific services.\n\n| Field | Type | Description | Default Value |\n| :--- | :--- | :--- | :--- |\n| `version` | Integer | Schema version for migration tracking. | `2` |\n| `input_ports` | List[str] | Saved JACK/PipeWire input port names. | `None` |\n| `save_path` | String | Permanent directory for saved sessions. | Current Working Directory |\n| `global_hotkey` | String | Key combination to trigger recording. | `<ctrl>+<alt>+space` |\n| `transcription` | Object | Settings for the Whisper server API. | `{\"enabled\": True, ...}` |\n\nSources: [src/omega13/config.py:#L24-L50]()\n\n### Operational Logic\nThe `ConfigManager` performs a shallow merge of defaults during initialization to ensure stability even if the JSON file is partially corrupted or outdated.\n\n```python\n# src/omega13/config.py:#L128-L135\nif \"transcription\" not in config:\n    config[\"transcription\"] = default_config[\"transcription\"]\nif \"sessions\" not in config:\n    config[\"sessions\"] = default_config[\"sessions\"]\nif \"global_hotkey\" not in config:\n    config[\"global_hotkey\"] = default_config[\"global_hotkey\"]\n```\n\n## Global Hotkey Mechanism\nThe system utilizes a dual-layered approach to hotkeys: an internal listener for X11/Windows environments and a CLI-based trigger for Wayland environments.\n\n### Internal Listener Architecture\nThe `GlobalHotkeyListener` uses the `pynput` library to monitor keyboard events. It includes a normalization step to resolve various key aliases (e.g., \"enter\" to `<enter>`) into a format compatible with `pynput`'s `GlobalHotKeys`.\n\n```mermaid\ngraph TD\n    A[App Initialization] --> B{Check PYNPUT_AVAILABLE}\n    B -- Yes --> C[Resolve Hotkey String]\n    C --> D[Start Keyboard Listener Thread]\n    D --> E[Wait for Key Combination]\n    E --> F[Invoke Callback: action_toggle_record]\n    B -- No --> G[Disable Internal Hotkey]\n```\nSources: [src/omega13/hotkeys.py:#L24-L85](), [src/omega13/app.py:#L145-L155]()\n\n### Wayland Support and the PID Mechanism\nBecause Wayland restricts global key sniffing, the application writes its process ID (PID) to `~/.local/share/omega13/omega13.pid`. This allows an external command, `omega13 --toggle`, to signal the running instance to start or stop recording. This is a functional workaround for the security constraints of modern display protocols.\n\nSources: [src/omega13/app.py:#L114-L122](), [README.md:#L87-L100]()\n\n## System Interaction Flow\nThe following sequence illustrates how a hotkey event propagates from the hardware level through the configuration-defined logic to trigger the audio engine.\n\n```mermaid\nsequenceDiagram\n    participant OS as Operating System\n    participant HK as GlobalHotkeyListener\n    participant APP as Omega13App\n    participant CFG as ConfigManager\n    participant ENG as AudioEngine\n\n    APP->>CFG: get_global_hotkey()\n    CFG-->>APP: \"<ctrl>+<alt>+space\"\n    APP->>HK: start(hotkey, callback)\n    \n    Note over OS, HK: User presses Ctrl+Alt+Space\n    OS->>HK: KeyPress Event\n    HK->>APP: call_from_thread(action_toggle_record)\n    \n    APP->>ENG: toggle_record()\n    ENG-->>APP: Recording Status (True/False)\n    APP->>OS: Desktop Notification (Optional)\n```\nSources: [src/omega13/app.py:#L145-L160](), [src/omega13/config.py:#L91-L93]()\n\n## Structural Observations\nThe system exhibits a dependency pattern where the UI help text is dynamically generated based on the configuration. If the hotkey resolution fails in `hotkeys.py`, the UI might still display the raw string, creating a minor visual disconnect if the underlying `pynput` listener fails to initialize. Furthermore, the `ConfigManager` includes a duplicate key entry for `\"save_to_file\": True` in its default dictionary, which is a harmless but redundant structural artifact.\n\nSources: [src/omega13/config.py:#L40-L41](), [src/omega13/app.py:#L210-L215]()\n\n## Conclusion\nThe configuration and hotkey systems provide the necessary flexibility for Omega-13 to operate across different Linux environments (X11 vs. Wayland). By decoupling the trigger mechanism (via `omega13 --toggle`) from the internal event listener, the architecture ensures that the core retroactive recording functionality remains accessible regardless of display server limitations. The `ConfigManager` acts as the single source of truth, synchronizing the audio engine's port requirements with the user's persistent preferences.",
      "filePaths": [
        "src/omega13/config.py",
        "src/omega13/hotkeys.py"
      ],
      "importance": "medium",
      "relatedPages": [
        "getting-started"
      ]
    },
    {
      "id": "whisper-server-deployment",
      "title": "Whisper Server Deployment",
      "content": "<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n- [compose.yml](https://github.com/b08x/omega-13/blob/main/compose.yml)\n- [src/omega13/transcription.py](https://github.com/b08x/omega-13/blob/main/src/omega13/transcription.py)\n- [src/omega13/app.py](https://github.com/b08x/omega-13/blob/main/src/omega13/app.py)\n- [README.md](https://github.com/b08x/omega-13/blob/main/README.md)\n- [CHANGELOG.md](https://github.com/b08x/omega-13/blob/main/CHANGELOG.md)\n- [src/omega13/config.py](https://github.com/b08x/omega-13/blob/main/src/omega13/config.py)\n</details>\n\n# Whisper Server Deployment\n\n## 1. Introduction\nThe Whisper Server Deployment represents the transcription backbone of the Omega-13 system. It functions as a containerized inference engine that processes audio files via an HTTP API. Structurally, the system decouples the high-latency, resource-intensive transcription task from the real-time audio capture engine. The deployment relies on a CUDA-enabled `whisper.cpp` implementation, facilitating GPU-accelerated speech-to-text processing which is then consumed by the Python-based frontend.\n\nSources: [compose.yml](), [src/omega13/transcription.py:#L1-L15](), [README.md]()\n\n## 2. Containerized Infrastructure\nThe deployment is orchestrated via Docker Compose, targeting a specialized CUDA image. The architecture prioritizes performance by mounting host directories for models and recordings, and by exposing hardware-level GPU access to the container.\n\n### Hardware and Resource Allocation\nThe server is configured to utilize NVIDIA GPUs through the `nvidia-container-toolkit`. Despite being a \"server,\" it operates with significant local dependencies, requiring specific model files (e.g., `ggml-large-v3-turbo-q5_0.bin`) to be present on the host filesystem.\n\n| Feature | Configuration / Value | Source |\n| :--- | :--- | :--- |\n| Base Image | `whisper-server-cuda:latest` | [compose.yml:#L5]() |\n| Port Mapping | `8080:8080` | [compose.yml:#L14-L15]() |\n| GPU Access | `nvidia.com/gpu=all` | [compose.yml:#L51-L52]() |\n| Memory Limit | `12G` | [compose.yml:#L61]() |\n| Default Threads | `8` | [compose.yml:#L42]() |\n\nSources: [compose.yml:#L5-L61]()\n\n## 3. Communication Protocol and Data Flow\nThe interaction between the Omega-13 application and the Whisper server follows a request-response pattern over HTTP. The `TranscriptionService` in the Python client manages this lifecycle, including health checks and file uploads.\n\n### Transcription Lifecycle\nThe system exhibits a rigid dependency on the server's availability. While the audio engine captures data locally, the utility of that data for transcription is entirely contingent on the container's state. The flow follows a sequence of audio finalization, HTTP POST transmission, and asynchronous result handling.\n\n```mermaid\nsequenceDiagram\n    participant App as Omega13App\n    participant Service as TranscriptionService\n    participant Server as Whisper Server (Docker)\n\n    App->>Service: _transcribe_file(audio_path)\n    activate Service\n    Service->>Server: GET / (Health Check)\n    Server-->>Service: 200 OK\n    Service->>Server: POST /inference (Audio Data)\n    activate Server\n    Note over Server: Processing via CUDA\n    Server-->>Service: JSON Result (Text/Segments)\n    deactivate Server\n    Service-->>App: TranscriptionResult\n    deactivate Service\n    App->>App: Update UI & Clipboard\n```\n*Note: The system performs a health check before attempting inference to prevent hanging on a dead container.*\n\nSources: [src/omega13/transcription.py:#L51-L75](), [src/omega13/app.py]()\n\n## 4. Configuration and Environment Variables\nThe server's behavior is dictated by environment variables and command-line flags defined in the compose file. These settings control the model path, threading, and specific inference optimizations.\n\n| Variable | Role | Observed Behavior |\n| :--- | :--- | :--- |\n| `WHISPER_MODEL` | Path to GGML model | Mandatory for server start. |\n| `WHISPER_THREADS` | CPU thread count | Set to 8 by default for parallel processing. |\n| `--convert` | Audio conversion | Enables ffmpeg-based pre-processing within the container. |\n| `--nf` | No fallback | Forces deterministic, faster inference by disabling temperature fallback. |\n\nSources: [compose.yml:#L26-L45]()\n\n## 5. Structural Observations and Dependencies\nThe deployment reveals a \"cooperative\" but fragile relationship between the host and the container.\n\n*   **Implicit Dependency Path:** The `compose.yml` uses hardcoded paths like `${HOME}/LLMOS/whisper.cpp/models`. If this specific directory structure doesn't exist on the host, the container fails silently or throws mount errors. It\u2019s a fucking brittle way to handle model distribution, requiring the user to manually populate the host filesystem before the \"automated\" deployment works.\n*   **Networking:** The `TranscriptionService` defaults to `http://localhost:8080`. While configurable via `config.json`, the application assumes a local or bridge-networked container by default.\n*   **Shutdown Mechanism:** The `TranscriptionService` implements a `_shutdown_event` (threading.Event) to allow for cooperative shutdown, ensuring that if the app exits, it doesn't leave orphaned HTTP requests hanging indefinitely.\n\nSources: [compose.yml:#L19-L20](), [src/omega13/transcription.py:#L48](), [src/omega13/config.py:#L30]()\n\n## 6. Conclusion\nThe Whisper Server Deployment is the heavy-lifting component of the Omega-13 architecture. It successfully abstracts complex CUDA/C++ dependencies behind a standard HTTP interface, allowing the Textual-based UI to remain responsive. However, the structural integrity of the system relies heavily on the user's local environment matching the expected volume mounts and GPU drivers, creating a high-friction boundary between the Python application and its transcription capabilities.\n\nSources: [compose.yml](), [README.md](), [CHANGELOG.md]()",
      "filePaths": [
        "Containerfile",
        "compose.yml"
      ],
      "importance": "high",
      "relatedPages": [
        "transcription-service"
      ]
    }
  ]
}